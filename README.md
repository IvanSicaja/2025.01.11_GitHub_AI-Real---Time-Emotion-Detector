**ğŸ§¾ ğŸ¯ Project Title: AI REAL-TIME EMOTION DETECTOR  
ğŸ“… Project Timeline:** January 2025 â€“ February 2025  
ğŸ¥ YouTube Demo: Not available  
ğŸ“¦ GitHub Source Code: [https://github.com/IvanSicaja/2025.01.11_GitHub_AI-Real---Time-Emotion-Detector](https://github.com/IvanSicaja/2025.01.11_GitHub_AI-Real---Time-Emotion-Detector?utm_source=chatgpt.com)  
\----------------------------------------------------------------------------------------------------------------

ğŸ·ï¸ My Personal Profiles: â¬‡ï¸  
ğŸ¥ Video Portfolio: To be added  
ğŸ“¦ GitHub Profile: <https://github.com/IvanSicaja>  
ğŸ”— LinkedIn: <https://www.linkedin.com/in/ivan-si%C4%8Daja-832682222>  
ğŸ¥ YouTube: <https://www.youtube.com/@ivan_sicaja>  
\----------------------------------------------------------------------------------------------------------------

### ğŸ“šğŸ” Project description: â¬‡ï¸â¬‡ï¸â¬‡ï¸

### ğŸ’¡ App Purpose

The purpose is to build a **real-time emotion detection app** that analyzes facial landmarks from video input and predicts emotions using a **CNN model** trained on facial landmark data.

### ğŸ§  How It Works

1. **Data Preparation**: Facial landmarks are extracted from videos using **MediaPipe Face Mesh**. A **custom script** automates this process: on a single click, it extracts landmarks from all videos in a folder and stores them in a database along with the corresponding **emotion label**, which is automatically derived from the video file name.
2. **Model Training**: A **TensorFlow CNN** is trained on the processed landmark data to classify three emotions: Happy, Neutral, Sad.
3. **Real-Time Detection**: For each video frame, landmarks are extracted, reshaped, and passed through the trained CNN to predict emotion. The predicted emotion is overlaid on the video in real time.
4. **Visualization**: OpenCV displays the video frames with face mesh landmarks and predicted emotion labels.

### âš ï¸ Note

1. **Real-world applications** require **larger datasets**, **more classes**, and **optimized models** for **robustness** and **scalability**.
2. **All videos** were sourced from [**www.pexels.com**](https://www.pexels.com?utm_source=chatgpt.com). **Author credits** are listed in â€œCreditsToVideoCreators.docxâ€. Per **Pexels licensing**, videos cannot be **copied, redistributed, or shared** beyond **personal** or **educational use**.

### ğŸ”§ Tech Stack

**Python, OpenCV, MediaPipe, TensorFlow/Keras, Pandas, NumPy, Matplotlib, Scikit-learn, Excel, CNN, Machine Learning, Deep Learning, Linux**

---

### ğŸ“¸ Project Snapshot

<p align="center">
  <img src="https://github.com/IvanSicaja/2025.01.11_GitHub_AI-Real---Time-Emotion-Detector/raw/main/0.1_GitHub/1.0_Description_4_media_key_messages_and_captions/2.0_Thumbnail_1.png" 
       alt="App Preview" 
       width="640" 
       height="360">
</p>

---

### ğŸ¥ Video Demonstration

TBD

---

### ğŸ“£ Hashtags Section

**\# #AI #RealTimeEmotionDetection #Python #OpenCV #MediaPipe #TensorFlow #DeepLearning #CNN #FacialLandmarks #MachineLearning #EmotionRecognition #DataScience #ComputerVision #AIProject #GitHub #FullStackDevelopment #Research #MLProject**
